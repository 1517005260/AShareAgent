from langchain_core.messages import HumanMessage
from src.agents.state import AgentState, show_agent_reasoning, show_workflow_status
from src.tools.openrouter_config import get_chat_completion
from src.utils.api_utils import agent_endpoint, log_llm_interaction
import json
import ast
import logging

# è·å–æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger('debate_room')


@agent_endpoint("debate_room", "è¾©è®ºå®¤ï¼Œåˆ†æå¤šç©ºåŒæ–¹è§‚ç‚¹ï¼Œå¾—å‡ºå¹³è¡¡çš„æŠ•èµ„ç»“è®º")
def debate_room_agent(state: AgentState):
    """Facilitates debate between bull and bear researchers to reach a balanced conclusion."""
    show_workflow_status("Debate Room")
    show_reasoning = state["metadata"]["show_reasoning"]
    logger.info("å¼€å§‹åˆ†æç ”ç©¶å‘˜è§‚ç‚¹å¹¶è¿›è¡Œè¾©è®º...")

    # æ”¶é›†æ‰€æœ‰ç ”ç©¶å‘˜ä¿¡æ¯ - å‘å‰å…¼å®¹è®¾è®¡ï¼ˆæ·»åŠ é˜²å¾¡æ€§æ£€æŸ¥ï¼‰
    researcher_messages = {}
    for msg in state["messages"]:
        # æ·»åŠ é˜²å¾¡æ€§æ£€æŸ¥ï¼Œç¡®ä¿ msg å’Œ msg.name ä¸ä¸º None
        if msg is None:
            continue
        if not hasattr(msg, 'name') or msg.name is None:
            continue
        if isinstance(msg.name, str) and msg.name.startswith("researcher_") and msg.name.endswith("_agent"):
            researcher_messages[msg.name] = msg
            logger.debug(f"æ”¶é›†åˆ°ç ”ç©¶å‘˜ä¿¡æ¯: {msg.name}")

    # ç¡®ä¿è‡³å°‘æœ‰çœ‹å¤šå’Œçœ‹ç©ºä¸¤ä¸ªç ”ç©¶å‘˜
    if "researcher_bull_agent" not in researcher_messages or "researcher_bear_agent" not in researcher_messages:
        logger.error(
            "ç¼ºå°‘å¿…è¦çš„ç ”ç©¶å‘˜æ•°æ®: researcher_bull_agent æˆ– researcher_bear_agent")
        raise ValueError(
            "Missing required researcher_bull_agent or researcher_bear_agent messages")

    # å¤„ç†ç ”ç©¶å‘˜æ•°æ®
    researcher_data = {}
    for name, msg in researcher_messages.items():
        # æ·»åŠ é˜²å¾¡æ€§æ£€æŸ¥ï¼Œç¡®ä¿ msg.content ä¸ä¸º None
        if not hasattr(msg, 'content') or msg.content is None:
            logger.warning(f"ç ”ç©¶å‘˜ {name} çš„æ¶ˆæ¯å†…å®¹ä¸ºç©º")
            continue
        try:
            data = json.loads(msg.content)
            logger.debug(f"æˆåŠŸè§£æ {name} çš„ JSON å†…å®¹")
        except (json.JSONDecodeError, TypeError):
            try:
                data = ast.literal_eval(msg.content)
                logger.debug(f"é€šè¿‡ ast.literal_eval è§£æ {name} çš„å†…å®¹")
            except (ValueError, SyntaxError, TypeError):
                # å¦‚æœæ— æ³•è§£æå†…å®¹ï¼Œè·³è¿‡æ­¤æ¶ˆæ¯
                logger.warning(f"æ— æ³•è§£æ {name} çš„æ¶ˆæ¯å†…å®¹ï¼Œå·²è·³è¿‡")
                continue
        researcher_data[name] = data

    # è·å–çœ‹å¤šå’Œçœ‹ç©ºç ”ç©¶å‘˜æ•°æ®ï¼ˆä¸ºäº†å…¼å®¹åŸæœ‰é€»è¾‘ï¼‰
    if "researcher_bull_agent" not in researcher_data or "researcher_bear_agent" not in researcher_data:
        logger.error("æ— æ³•è§£æå¿…è¦çš„ç ”ç©¶å‘˜æ•°æ®")
        raise ValueError(
            "Could not parse required researcher_bull_agent or researcher_bear_agent messages")

    bull_thesis = researcher_data["researcher_bull_agent"]
    bear_thesis = researcher_data["researcher_bear_agent"]
    logger.info(
        f"å·²è·å–çœ‹å¤šè§‚ç‚¹(ç½®ä¿¡åº¦: {bull_thesis.get('confidence', 0)})å’Œçœ‹ç©ºè§‚ç‚¹(ç½®ä¿¡åº¦: {bear_thesis.get('confidence', 0)})")

    # æ¯”è¾ƒç½®ä¿¡åº¦çº§åˆ«
    bull_confidence = bull_thesis.get("confidence", 0)
    bear_confidence = bear_thesis.get("confidence", 0)

    # åˆ†æè¾©è®ºè§‚ç‚¹
    debate_summary = []
    debate_summary.append("Bullish Arguments:")
    for point in bull_thesis.get("thesis_points", []):
        debate_summary.append(f"+ {point}")

    debate_summary.append("\nBearish Arguments:")
    for point in bear_thesis.get("thesis_points", []):
        debate_summary.append(f"- {point}")

    # æ”¶é›†æ‰€æœ‰ç ”ç©¶å‘˜çš„è®ºç‚¹ï¼Œå‡†å¤‡å‘ç»™ LLM
    all_perspectives = {}
    for name, data in researcher_data.items():
        perspective = data.get("perspective", name.replace(
            "researcher_", "").replace("_agent", ""))
        all_perspectives[perspective] = {
            "confidence": data.get("confidence", 0),
            "thesis_points": data.get("thesis_points", [])
        }

    logger.info(f"å‡†å¤‡è®© LLM åˆ†æ {len(all_perspectives)} ä¸ªç ”ç©¶å‘˜çš„è§‚ç‚¹")

    # æ„å»ºå‘é€ç»™ LLM çš„æç¤º
    llm_prompt = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹æŠ•èµ„ç ”ç©¶å‘˜çš„è§‚ç‚¹ï¼Œå¹¶ç»™å‡ºä½ çš„ç¬¬ä¸‰æ–¹åˆ†æ:

"""
    for perspective, data in all_perspectives.items():
        llm_prompt += f"\n{perspective.upper()} è§‚ç‚¹ (ç½®ä¿¡åº¦: {data['confidence']}):\n"
        for point in data["thesis_points"]:
            llm_prompt += f"- {point}\n"

    llm_prompt += """
è¯·æä¾›ä»¥ä¸‹æ ¼å¼çš„ JSON å›å¤:
{
    "analysis": "ä½ çš„è¯¦ç»†åˆ†æï¼Œè¯„ä¼°å„æ–¹è§‚ç‚¹çš„ä¼˜åŠ£ï¼Œå¹¶æŒ‡å‡ºä½ è®¤ä¸ºæœ€æœ‰è¯´æœåŠ›çš„è®ºç‚¹",
    "score": 0.5,  // ä½ çš„è¯„åˆ†ï¼Œä» -1.0(æåº¦çœ‹ç©º) åˆ° 1.0(æåº¦çœ‹å¤š)ï¼Œ0 è¡¨ç¤ºä¸­æ€§
    "reasoning": "ä½ ç»™å‡ºè¿™ä¸ªè¯„åˆ†çš„ç®€è¦ç†ç”±"
}

åŠ¡å¿…ç¡®ä¿ä½ çš„å›å¤æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼Œä¸”åŒ…å«ä¸Šè¿°æ‰€æœ‰å­—æ®µã€‚å›å¤å¿…é¡»ä½¿ç”¨è‹±æ–‡ï¼Œä¸è¦ä½¿ç”¨ä¸­æ–‡æˆ–å…¶ä»–è¯­è¨€ã€‚
"""

    # è°ƒç”¨ LLM è·å–ç¬¬ä¸‰æ–¹è§‚ç‚¹
    llm_response = None
    llm_analysis = None
    llm_score = 0  # é»˜è®¤ä¸ºä¸­æ€§
    try:
        logger.info("å¼€å§‹è°ƒç”¨ LLM è·å–ç¬¬ä¸‰æ–¹åˆ†æ...")
        messages = [
            {"role": "system", "content": "You are a professional financial analyst. Please provide your analysis in English only, not in Chinese or any other language."},
            {"role": "user", "content": llm_prompt}
        ]

        # ä½¿ç”¨log_llm_interactionè£…é¥°å™¨è®°å½•LLMäº¤äº’
        llm_response = log_llm_interaction(state)(
            lambda: get_chat_completion(messages)
        )()

        logger.info("LLM è¿”å›å“åº”å®Œæˆ")

        # è§£æ LLM è¿”å›çš„ JSON
        if llm_response:
            try:
                # å°è¯•æå– JSON éƒ¨åˆ†
                json_start = llm_response.find('{')
                json_end = llm_response.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    json_str = llm_response[json_start:json_end]
                    llm_analysis = json.loads(json_str)
                    llm_score = float(llm_analysis.get("score", 0))
                    # ç¡®ä¿åˆ†æ•°åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    llm_score = max(min(llm_score, 1.0), -1.0)
                    logger.info(f"æˆåŠŸè§£æ LLM å›å¤ï¼Œè¯„åˆ†: {llm_score}")
                    logger.debug(
                        f"LLM åˆ†æå†…å®¹: {llm_analysis.get('analysis', 'æœªæä¾›åˆ†æ')[:100]}...")
            except Exception as e:
                # å¦‚æœè§£æå¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶ä½¿ç”¨é»˜è®¤å€¼
                logger.error(f"è§£æ LLM å›å¤å¤±è´¥: {e}")
                llm_analysis = {"analysis": "Failed to parse LLM response",
                                "score": 0, "reasoning": "Parsing error"}
    except Exception as e:
        logger.error(f"è°ƒç”¨ LLM å¤±è´¥: {e}")
        llm_analysis = {"analysis": "LLM API call failed",
                        "score": 0, "reasoning": "API error"}

    # Enhanced A-share specific confidence calculation
    confidence_diff = bull_confidence - bear_confidence
    
    # Aè‚¡ç‰¹è‰²å› ç´ è°ƒæ•´
    ashare_adjustments = {
        'policy_factor': 0.0,
        'liquidity_factor': 0.0, 
        'volatility_factor': 0.0,
        'sentiment_extreme': 0.0
    }
    
    # æ£€æŸ¥æ”¿ç­–æ•æ„Ÿæ€§
    bull_reasoning = str(bull_thesis.get('reasoning', ''))
    bear_reasoning = str(bear_thesis.get('reasoning', ''))
    
    if 'policy' in bull_reasoning.lower() or 'policy' in bear_reasoning.lower():
        ashare_adjustments['policy_factor'] = 0.1 if bull_confidence > bear_confidence else -0.1
        
    # æ£€æŸ¥æµåŠ¨æ€§é£é™©
    if 'liquidity' in bear_reasoning.lower():
        ashare_adjustments['liquidity_factor'] = -0.05
        
    # æ£€æŸ¥æƒ…ç»ªæç«¯æƒ…å†µ
    if abs(confidence_diff) > 0.7:
        ashare_adjustments['sentiment_extreme'] = -0.1 * abs(confidence_diff)
    
    # åº”ç”¨Aè‚¡è°ƒæ•´
    total_adjustment = sum(ashare_adjustments.values())
    adjusted_confidence_diff = confidence_diff + total_adjustment
    
    # å¢åŠ LLMæƒé‡ä»¥æ›´å¥½å¤„ç†Aè‚¡å¤æ‚æ€§
    llm_weight = 0.4
    
    # ç»¼åˆè®¡ç®—ï¼Œç»“åˆè°ƒæ•´åçš„ç½®ä¿¡åº¦å’ŒLLMåˆ†æ
    mixed_confidence_diff = (1 - llm_weight) * adjusted_confidence_diff + llm_weight * llm_score
    
    logger.info(
        f"Aè‚¡ç‰¹è‰²è°ƒæ•´: åŸå§‹å·®å¼‚={confidence_diff:.3f}, è°ƒæ•´å={adjusted_confidence_diff:.3f}, LLMè¯„åˆ†={llm_score:.3f}, æœ€ç»ˆå·®å¼‚={mixed_confidence_diff:.3f}")
    logger.info(f"Aè‚¡è°ƒæ•´å› ç´ : {ashare_adjustments}")

    # Aè‚¡ç‰¹è‰²å†³ç­–é€»è¾‘ä¼˜åŒ–
    market_volatility = abs(bull_confidence - bear_confidence)
    adaptive_threshold = 0.1 + min(market_volatility * 0.1, 0.05)  # åŠ¨æ…‹é˜ˆå€¼
    
    # ç‰¹æ®Šæƒ…å†µæ£€æŸ¥
    special_conditions = {
        'policy_sensitive': ashare_adjustments['policy_factor'] != 0,
        'high_volatility': market_volatility > 0.6,
        'extreme_sentiment': abs(adjusted_confidence_diff) > 0.8,
        'liquidity_concern': ashare_adjustments['liquidity_factor'] < 0
    }
    
    # å†³ç­–é€»è¾‘ä¼˜åŒ–
    if abs(mixed_confidence_diff) < adaptive_threshold:
        final_signal = "neutral"
        reasoning = f"Aè‚¡è¾©è®ºå‡è¡¡ï¼ŒåŒæ–¹è®ºç‚¹éƒ½æœ‰åˆç†æ€§ã€‚é˜ˆå€¼: {adaptive_threshold:.3f}"
        confidence = max(bull_confidence, bear_confidence)
    elif mixed_confidence_diff > 0:
        confidence_level = "å¼ºçƒˆ" if mixed_confidence_diff > 0.5 else "æ¸©å’Œ"
        final_signal = "bullish"
        reasoning = f"{confidence_level}çœ‹å¤šä¿¡å·ï¼Œå¤šå¤´è®ºç‚¹æ›´æœ‰è¯´æœåŠ›ã€‚è¯„åˆ†: {mixed_confidence_diff:.3f}"
        confidence = bull_confidence
    else:
        risk_level = "é«˜é£é™©" if mixed_confidence_diff < -0.5 else "ä¸­ç­‰é£é™©"
        final_signal = "bearish"
        reasoning = f"{risk_level}çœ‹ç©ºä¿¡å·ï¼Œç©ºå¤´è®ºç‚¹æ›´æœ‰è¯´æœåŠ›ã€‚è¯„åˆ†: {mixed_confidence_diff:.3f}"
        confidence = bear_confidence
    
    # ç‰¹æ®Šæƒ…å†µè°ƒæ•´
    if special_conditions['policy_sensitive']:
        reasoning += " â—æ”¿ç­–æ•æ„Ÿæ€§é«˜"
    if special_conditions['liquidity_concern']:
        reasoning += " âš ï¸æµåŠ¨æ€§é£é™©"
    if special_conditions['high_volatility']:
        reasoning += " ğŸ“ˆæ³¢åŠ¨æ€§è¾ƒå¤§"

    logger.info(f"æœ€ç»ˆæŠ•èµ„ä¿¡å·: {final_signal}, ç½®ä¿¡åº¦: {confidence}")

    # Aè‚¡ç‰¹è‰²è¾©è®ºç»“æœ
    message_content = {
        "signal": final_signal,
        "confidence": confidence,
        "bull_confidence": bull_confidence,
        "bear_confidence": bear_confidence,
        "confidence_diff": confidence_diff,
        "adjusted_confidence_diff": adjusted_confidence_diff,
        "llm_score": llm_score if llm_analysis else None,
        "llm_analysis": llm_analysis["analysis"] if llm_analysis and "analysis" in llm_analysis else None,
        "llm_reasoning": llm_analysis["reasoning"] if llm_analysis and "reasoning" in llm_analysis else None,
        "mixed_confidence_diff": mixed_confidence_diff,
        "debate_summary": debate_summary,
        "reasoning": reasoning,
        "ashare_factors": {
            "policy_sensitivity": special_conditions['policy_sensitive'],
            "liquidity_concerns": special_conditions['liquidity_concern'],
            "volatility_level": market_volatility,
            "adaptive_threshold": adaptive_threshold,
            "adjustments_applied": ashare_adjustments
        },
        "decision_quality": {
            "consensus_strength": 1 - market_volatility,
            "argument_balance": min(bull_confidence, bear_confidence) / max(bull_confidence, bear_confidence) if max(bull_confidence, bear_confidence) > 0 else 0,
            "llm_agreement": 1 - abs(llm_score - (adjusted_confidence_diff / 2)) if llm_score is not None else 0
        }
    }

    message = HumanMessage(
        content=json.dumps(message_content, ensure_ascii=False),
        name="debate_room_agent",
    )

    if show_reasoning:
        show_agent_reasoning(message_content, "Debate Room")
        # ä¿å­˜æ¨ç†ä¿¡æ¯åˆ°metadataä¾›APIä½¿ç”¨
        state["metadata"]["agent_reasoning"] = message_content

    show_workflow_status("Aè‚¡ç‰¹è‰²è¾©è®ºå®¤", "completed")
    logger.info(f"Aè‚¡è¾©è®ºå®¤åˆ†æå®Œæˆ: {final_signal}, ç½®ä¿¡åº¦: {confidence:.3f}")
    return {
        "messages": state["messages"] + [message],
        "data": {
            **state["data"],
            "debate_analysis": message_content,
            "ashare_debate_metrics": {
                "volatility_level": market_volatility,
                "policy_sensitivity": special_conditions['policy_sensitive'],
                "decision_confidence": confidence,
                "consensus_quality": message_content["decision_quality"]["consensus_strength"]
            }
        },
        "metadata": {
            **state["metadata"],
            "debate_enhanced": True,
            "adaptive_threshold": adaptive_threshold,
            "special_conditions": special_conditions
        },
    }
