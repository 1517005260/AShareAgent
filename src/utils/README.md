# æ™ºèƒ½æŠ•èµ„ç³»ç»Ÿ - æ ¸å¿ƒå·¥å…·æ¨¡å—

## æ¦‚è¿°

æ ¸å¿ƒå·¥å…·æ¨¡å—æä¾›äº†æ™ºèƒ½æŠ•èµ„ç³»ç»Ÿçš„åŸºç¡€è®¾æ–½å’Œå…±äº«åŠŸèƒ½ï¼ŒåŒ…æ‹¬é…ç½®ç®¡ç†ã€LLMå®¢æˆ·ç«¯ã€æ—¥å¿—ç³»ç»Ÿã€åºåˆ—åŒ–å·¥å…·ã€å¼‚å¸¸å¤„ç†ç­‰æ ¸å¿ƒç»„ä»¶ã€‚è¿™äº›å·¥å…·æ¨¡å—ä¸ºæ•´ä¸ªç³»ç»Ÿçš„å„ä¸ªç»„ä»¶æä¾›ç»Ÿä¸€çš„æœåŠ¡å’Œæ¥å£ã€‚

## ç³»ç»Ÿæ¶æ„

```
src/utils/
â”œâ”€â”€ __init__.py                    # æ¨¡å—åˆå§‹åŒ–
â”œâ”€â”€ config_manager.py              # ç»Ÿä¸€é…ç½®ç®¡ç†
â”œâ”€â”€ llm_clients.py                 # LLMå®¢æˆ·ç«¯å°è£…
â”œâ”€â”€ logging_config.py              # æ—¥å¿—é…ç½®ç³»ç»Ÿ
â”œâ”€â”€ serialization.py               # å¯¹è±¡åºåˆ—åŒ–å·¥å…·
â”œâ”€â”€ exceptions.py                  # è‡ªå®šä¹‰å¼‚å¸¸ç±»
â”œâ”€â”€ api_utils.py                   # APIå·¥å…·å’Œè£…é¥°å™¨
â”œâ”€â”€ llm_interaction_logger.py      # LLMäº¤äº’æ—¥å¿—è®°å½•
â”œâ”€â”€ output_logger.py               # è¾“å‡ºé‡å®šå‘æ—¥å¿—
â”œâ”€â”€ structured_terminal.py         # ç»“æ„åŒ–ç»ˆç«¯è¾“å‡º
â””â”€â”€ README.md                      # è¯´æ˜æ–‡æ¡£
```

## æ ¸å¿ƒå·¥å…·è¯¦è¿°

### 1. é…ç½®ç®¡ç† (config_manager.py)

ç»Ÿä¸€çš„é…ç½®ç®¡ç†ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§é…ç½®ç±»å‹å’Œç¯å¢ƒå˜é‡è‡ªåŠ¨åŠ è½½ã€‚

#### ä¸»è¦é…ç½®ç±»

- **LLMConfig**: LLMç›¸å…³é…ç½®
- **SystemConfig**: ç³»ç»Ÿçº§é…ç½®
- **AgentConfig**: Agentè¡Œä¸ºé…ç½®
- **MarketDataConfig**: å¸‚åœºæ•°æ®é…ç½®

#### ä½¿ç”¨æ–¹æ³•

```python
from src.utils.config_manager import get_config, get_llm_config

# è·å–å…¨å±€é…ç½®å®ä¾‹
config = get_config()

# è®¿é—®ä¸åŒé…ç½®
llm_config = config.llm
system_config = config.system
agent_config = config.agent
market_data_config = config.market_data

# ä¾¿æ·å‡½æ•°
llm_config = get_llm_config()
```

#### ç¯å¢ƒå˜é‡é…ç½®

```bash
# LLMé…ç½®
GEMINI_API_KEY=your-gemini-api-key
GEMINI_MODEL=gemini-1.5-flash

# OpenAIå…¼å®¹APIé…ç½®
OPENAI_COMPATIBLE_API_KEY=your-api-key
OPENAI_COMPATIBLE_BASE_URL=https://api.example.com/v1
OPENAI_COMPATIBLE_MODEL=claude-3-haiku

# ç³»ç»Ÿé…ç½®
LOG_LEVEL=INFO
MAX_OUTPUT_SIZE=10000
CACHE_ENABLED=true
CACHE_TTL=3600

# Agenté…ç½®
DEFAULT_CONFIDENCE_THRESHOLD=0.5
MAX_NEWS_COUNT=100
SENTIMENT_ANALYSIS_DAYS=7
RISK_SCORE_THRESHOLD=8
```

#### é…ç½®éªŒè¯

```python
config = get_config()
if config.validate_configuration():
    print("é…ç½®éªŒè¯é€šè¿‡")
else:
    print("é…ç½®éªŒè¯å¤±è´¥")

# ç”Ÿæˆç¯å¢ƒå˜é‡æ¨¡æ¿
config.save_env_template(".env.example")
```

### 2. LLMå®¢æˆ·ç«¯ (llm_clients.py)

ç»Ÿä¸€çš„LLMå®¢æˆ·ç«¯å°è£…ï¼Œæ”¯æŒå¤šç§LLMæä¾›å•†å’Œè‡ªåŠ¨é‡è¯•æœºåˆ¶ã€‚

#### æ”¯æŒçš„å®¢æˆ·ç«¯

- **GeminiClient**: Google Gemini APIå®¢æˆ·ç«¯
- **OpenAICompatibleClient**: OpenAIå…¼å®¹APIå®¢æˆ·ç«¯

#### ä½¿ç”¨æ–¹æ³•

```python
from src.utils.llm_clients import get_chat_completion, LLMClientFactory

# ç®€å•è°ƒç”¨ï¼ˆè‡ªåŠ¨é€‰æ‹©å®¢æˆ·ç«¯ï¼‰
messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆ"},
    {"role": "user", "content": "åˆ†æä¸€ä¸‹è¿™åªè‚¡ç¥¨çš„æŠ•èµ„ä»·å€¼"}
]

response = get_chat_completion(
    messages=messages,
    max_retries=3,
    client_type="auto"  # è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„å®¢æˆ·ç«¯
)

# æŒ‡å®šå®¢æˆ·ç«¯ç±»å‹
gemini_response = get_chat_completion(
    messages=messages,
    client_type="gemini"
)

openai_response = get_chat_completion(
    messages=messages,
    client_type="openai_compatible"
)
```

#### å·¥å‚æ¨¡å¼åˆ›å»ºå®¢æˆ·ç«¯

```python
from src.utils.llm_clients import LLMClientFactory

# åˆ›å»ºGeminiå®¢æˆ·ç«¯
gemini_client = LLMClientFactory.create_client(
    client_type="gemini",
    api_key="your-api-key",
    model="gemini-1.5-flash"
)

# åˆ›å»ºOpenAIå…¼å®¹å®¢æˆ·ç«¯
openai_client = LLMClientFactory.create_client(
    client_type="openai_compatible",
    api_key="your-api-key",
    base_url="https://api.example.com/v1",
    model="claude-3-haiku"
)

# ç›´æ¥è°ƒç”¨
response = gemini_client.get_completion(messages)
```

#### é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†

```python
# å¸¦é‡è¯•çš„LLMè°ƒç”¨
response = get_chat_completion(
    messages=messages,
    max_retries=5,           # æœ€å¤§é‡è¯•æ¬¡æ•°
    initial_retry_delay=1,   # åˆå§‹é‡è¯•å»¶è¿Ÿ
    client_type="auto"
)

# é”™è¯¯å¤„ç†
if response is None:
    print("LLMè°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
else:
    print(f"æˆåŠŸè·å–å“åº”: {response}")
```

### 3. æ—¥å¿—é…ç½® (logging_config.py)

ç»Ÿä¸€çš„æ—¥å¿—é…ç½®ç³»ç»Ÿï¼Œæ”¯æŒæ§åˆ¶å°å’Œæ–‡ä»¶åŒé‡è¾“å‡ºã€‚

#### ä½¿ç”¨æ–¹æ³•

```python
from src.utils.logging_config import setup_logger, SUCCESS_ICON, ERROR_ICON, WAIT_ICON

# åˆ›å»ºlogger
logger = setup_logger('my_module')

# ä½¿ç”¨é¢„å®šä¹‰å›¾æ ‡
logger.info(f"{SUCCESS_ICON} æ“ä½œæˆåŠŸå®Œæˆ")
logger.error(f"{ERROR_ICON} æ“ä½œæ‰§è¡Œå¤±è´¥")
logger.info(f"{WAIT_ICON} æ­£åœ¨å¤„ç†è¯·æ±‚...")
```

#### æ—¥å¿—çº§åˆ«é…ç½®

- **æ§åˆ¶å°**: INFOçº§åˆ«åŠä»¥ä¸Š
- **æ–‡ä»¶**: DEBUGçº§åˆ«åŠä»¥ä¸Š
- **æ–‡ä»¶ä½ç½®**: `logs/{module_name}.log`

#### è‡ªå®šä¹‰æ—¥å¿—ç›®å½•

```python
# æŒ‡å®šæ—¥å¿—ç›®å½•
logger = setup_logger('my_module', log_dir='/custom/log/dir')
```

### 4. åºåˆ—åŒ–å·¥å…· (serialization.py)

æä¾›å¤æ‚Pythonå¯¹è±¡åˆ°JSONå¯åºåˆ—åŒ–æ ¼å¼çš„è½¬æ¢ã€‚

#### ä½¿ç”¨æ–¹æ³•

```python
from src.utils.serialization import serialize_agent_state

# åºåˆ—åŒ–AgentçŠ¶æ€
state = {
    "data": {"ticker": "600519"},
    "timestamp": datetime.now(),
    "pandas_data": some_dataframe,
    "custom_object": some_custom_object
}

serialized = serialize_agent_state(state)
print(json.dumps(serialized, indent=2))
```

#### æ”¯æŒçš„å¯¹è±¡ç±»å‹

- **åŸºç¡€ç±»å‹**: int, float, bool, str, None
- **å®¹å™¨ç±»å‹**: list, tuple, dict
- **æ—¥æœŸæ—¶é—´**: datetimeå¯¹è±¡ â†’ ISOæ ¼å¼å­—ç¬¦ä¸²
- **Pandaså¯¹è±¡**: DataFrame, Series â†’ dictæ ¼å¼
- **è‡ªå®šä¹‰å¯¹è±¡**: å…·æœ‰`__dict__`å±æ€§çš„å¯¹è±¡
- **LangChainæ¶ˆæ¯**: å…·æœ‰contentå’Œtypeå±æ€§çš„å¯¹è±¡

#### é”™è¯¯æ¢å¤

```python
# å¦‚æœåºåˆ—åŒ–å¤±è´¥ï¼Œä¼šè¿”å›é”™è¯¯ä¿¡æ¯
result = serialize_agent_state(problematic_state)
if result.get("serialization_error"):
    print(f"åºåˆ—åŒ–å¤±è´¥: {result['error']}")
```

### 5. å¼‚å¸¸å¤„ç† (exceptions.py)

å®šä¹‰äº†ç³»ç»Ÿä¸“ç”¨çš„å¼‚å¸¸ç±»å’Œé”™è¯¯æ¢å¤ç­–ç•¥ã€‚

#### å¼‚å¸¸ç±»å±‚æ¬¡

```python
AShareAgentException                 # åŸºç¡€å¼‚å¸¸ç±»
â”œâ”€â”€ DataValidationError             # æ•°æ®éªŒè¯é”™è¯¯
â”œâ”€â”€ LLMConnectionError              # LLMè¿æ¥é”™è¯¯
â”œâ”€â”€ MarketDataError                 # å¸‚åœºæ•°æ®é”™è¯¯
â”œâ”€â”€ AgentExecutionError             # Agentæ‰§è¡Œé”™è¯¯
â”œâ”€â”€ ConfigurationError              # é…ç½®é”™è¯¯
â””â”€â”€ PortfolioError                  # æŠ•èµ„ç»„åˆé”™è¯¯
```

#### ä½¿ç”¨æ–¹æ³•

```python
from src.utils.exceptions import MarketDataError, ErrorRecoveryStrategy

try:
    # å¸‚åœºæ•°æ®è·å–é€»è¾‘
    data = get_market_data(ticker)
except MarketDataError as e:
    print(f"å¸‚åœºæ•°æ®é”™è¯¯: {e}")
    print(f"è‚¡ç¥¨ä»£ç : {e.ticker}")
    print(f"æ•°æ®ç±»å‹: {e.data_type}")
    
    # ä½¿ç”¨é”™è¯¯æ¢å¤ç­–ç•¥
    fallback_data = ErrorRecoveryStrategy.get_safe_price_data()
```

#### é”™è¯¯æ¢å¤ç­–ç•¥

```python
# è·å–é»˜è®¤åˆ†æç»“æœ
default_result = ErrorRecoveryStrategy.get_default_analysis_result(
    agent_name="technical_agent",
    error_msg="æ•°æ®è·å–å¤±è´¥"
)

# è·å–å®‰å…¨çš„è´¢åŠ¡æŒ‡æ ‡
safe_metrics = ErrorRecoveryStrategy.get_safe_financial_metrics()

# è·å–å®‰å…¨çš„ä»·æ ¼æ•°æ®
safe_prices = ErrorRecoveryStrategy.get_safe_price_data()
```

### 6. APIå·¥å…· (api_utils.py)

æä¾›Agent APIè£…é¥°å™¨å’ŒLLMäº¤äº’æ—¥å¿—åŠŸèƒ½ã€‚

#### Agentç«¯ç‚¹è£…é¥°å™¨

```python
from src.utils.api_utils import agent_endpoint

@agent_endpoint("sentiment", "æƒ…æ„Ÿåˆ†æä»£ç†")
def sentiment_agent(state):
    # Agentæ‰§è¡Œé€»è¾‘
    result = analyze_sentiment(state)
    return result
```

#### LLMäº¤äº’æ—¥å¿—è£…é¥°å™¨

```python
from src.utils.api_utils import log_llm_interaction

# è£…é¥°å™¨æ¨¡å¼
@log_llm_interaction(state)
def my_llm_function(messages, **kwargs):
    return get_chat_completion(messages, **kwargs)

# ç›´æ¥è°ƒç”¨æ¨¡å¼
logger = log_llm_interaction("agent_name")
response = some_llm_call()
logger(request_data, response)
```

#### APIæœåŠ¡å™¨å¯åŠ¨

```python
from src.utils.api_utils import start_api_server
import threading

# åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­å¯åŠ¨APIæœåŠ¡å™¨
stop_event = threading.Event()
server_thread = threading.Thread(
    target=start_api_server,
    args=("0.0.0.0", 8000, stop_event),
    daemon=True
)
server_thread.start()

# åœæ­¢æœåŠ¡å™¨
stop_event.set()
```

### 7. LLMäº¤äº’æ—¥å¿—è®°å½• (llm_interaction_logger.py)

åŸºäºContext Variablesçš„LLMäº¤äº’æ—¥å¿—ç³»ç»Ÿã€‚

#### ä¸Šä¸‹æ–‡å˜é‡

```python
from src.utils.llm_interaction_logger import (
    log_storage_context,
    current_agent_name_context,
    current_run_id_context
)

# è®¾ç½®ä¸Šä¸‹æ–‡
log_storage_context.set(storage_instance)
current_agent_name_context.set("fundamentals_agent")
current_run_id_context.set("run_123")
```

#### Agentæ‰§è¡Œè£…é¥°å™¨

```python
from src.utils.llm_interaction_logger import log_agent_execution

@log_agent_execution("fundamentals_agent")
def fundamentals_agent(state):
    # Agenté€»è¾‘
    result = analyze_fundamentals(state)
    return result
```

#### LLMè°ƒç”¨åŒ…è£…

```python
from src.utils.llm_interaction_logger import wrap_llm_call
from src.utils.llm_clients import get_chat_completion

# åŒ…è£…LLMè°ƒç”¨å‡½æ•°
wrapped_llm_call = wrap_llm_call(get_chat_completion)

# ä½¿ç”¨åŒ…è£…åçš„å‡½æ•°ï¼ˆä¼šè‡ªåŠ¨è®°å½•æ—¥å¿—ï¼‰
response = wrapped_llm_call(messages)
```

#### è¾“å‡ºæ•è·

```python
from src.utils.llm_interaction_logger import OutputCapture

with OutputCapture() as capture:
    print("è¿™ä¼šè¢«æ•è·")
    logger.info("è¿™ä¹Ÿä¼šè¢«æ•è·")

print(f"æ•è·çš„è¾“å‡º: {capture.outputs}")
```

### 8. è¾“å‡ºæ—¥å¿— (output_logger.py)

é‡å®šå‘stdoutåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°çš„å·¥å…·ã€‚

#### ä½¿ç”¨æ–¹æ³•

```python
from src.utils.output_logger import OutputLogger
import sys

# é‡å®šå‘stdout
output_logger = OutputLogger("custom_output.txt")
sys.stdout = output_logger

print("è¿™ä¼šåŒæ—¶æ˜¾ç¤ºåœ¨æ§åˆ¶å°å’Œæ–‡ä»¶ä¸­")

# æ¢å¤åŸå§‹stdout
sys.stdout = output_logger.terminal
```

#### è‡ªåŠ¨æ—¶é—´æˆ³æ–‡ä»¶å

```python
# ä¸æŒ‡å®šæ–‡ä»¶åï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
output_logger = OutputLogger()  # logs/output_20240131_143052.txt
```

### 9. ç»“æ„åŒ–ç»ˆç«¯è¾“å‡º (structured_terminal.py)

ç¾è§‚çš„ç»ˆç«¯è¾“å‡ºæ ¼å¼åŒ–å·¥å…·ã€‚

#### ä½¿ç”¨æ–¹æ³•

```python
from src.utils.structured_terminal import (
    StructuredTerminalOutput,
    print_structured_output,
    terminal
)

# ä½¿ç”¨å…¨å±€ç»ˆç«¯å®ä¾‹
terminal.set_metadata("ticker", "600519")
terminal.set_metadata("start_date", "2024-01-01")
terminal.set_metadata("end_date", "2024-01-31")

# æ·»åŠ Agentæ•°æ®
terminal.add_agent_data("fundamentals_agent", {
    "signal": "bullish",
    "confidence": 0.8,
    "reasoning": "åŸºæœ¬é¢åˆ†ææ˜¾ç¤ºå…¬å¸è´¢åŠ¡çŠ¶å†µè‰¯å¥½"
})

# æ‰“å°æ ¼å¼åŒ–è¾“å‡º
terminal.print_output()
```

#### ä»å·¥ä½œæµçŠ¶æ€ç”Ÿæˆè¾“å‡º

```python
# ç›´æ¥ä»æœ€ç»ˆçŠ¶æ€ç”Ÿæˆç»“æ„åŒ–è¾“å‡º
final_state = {
    "data": {"ticker": "600519"},
    "metadata": {"all_agent_reasoning": {...}}
}

print_structured_output(final_state)
```

#### è‡ªå®šä¹‰Agentæ˜ å°„

```python
# åœ¨structured_terminal.pyä¸­æ·»åŠ æ–°Agent
AGENT_MAP["new_agent"] = {
    "icon": "ğŸ”§", 
    "name": "æ–°åˆ†æå·¥å…·"
}

AGENT_ORDER.append("new_agent")
```

## é›†æˆä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´çš„Agentå¼€å‘ç¤ºä¾‹

```python
# å¯¼å…¥å¿…è¦çš„å·¥å…·
from src.utils.config_manager import get_config
from src.utils.llm_clients import get_chat_completion
from src.utils.logging_config import setup_logger, SUCCESS_ICON, ERROR_ICON
from src.utils.api_utils import agent_endpoint, log_llm_interaction
from src.utils.exceptions import AgentExecutionError, ErrorRecoveryStrategy
from src.utils.serialization import serialize_agent_state

# è®¾ç½®æ—¥å¿—
logger = setup_logger('custom_agent')

@agent_endpoint("custom_agent", "è‡ªå®šä¹‰åˆ†æä»£ç†")
def custom_agent(state):
    """è‡ªå®šä¹‰åˆ†æä»£ç†ç¤ºä¾‹"""
    try:
        # è·å–é…ç½®
        config = get_config()
        
        # æ•°æ®éªŒè¯
        ticker = state["data"].get("ticker")
        if not ticker:
            raise AgentExecutionError("ç¼ºå°‘è‚¡ç¥¨ä»£ç ", "custom_agent")
        
        logger.info(f"{SUCCESS_ICON} å¼€å§‹åˆ†æè‚¡ç¥¨: {ticker}")
        
        # æ„é€ LLMè¯·æ±‚
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆ"
            },
            {
                "role": "user", 
                "content": f"è¯·åˆ†æè‚¡ç¥¨ {ticker} çš„æŠ•èµ„ä»·å€¼"
            }
        ]
        
        # è°ƒç”¨LLMï¼ˆå¸¦æ—¥å¿—è®°å½•ï¼‰
        llm_logger = log_llm_interaction("custom_agent")
        response = get_chat_completion(
            messages=messages,
            max_retries=config.llm.max_retries,
            client_type="auto"
        )
        llm_logger(messages, response)
        
        if not response:
            raise AgentExecutionError("LLMè°ƒç”¨å¤±è´¥", "custom_agent")
        
        # å¤„ç†ç»“æœ
        analysis_result = {
            "signal": "neutral",
            "confidence": 0.6,
            "reasoning": response,
            "ticker": ticker
        }
        
        logger.info(f"{SUCCESS_ICON} åˆ†æå®Œæˆ")
        
        # æ›´æ–°çŠ¶æ€
        new_state = {
            "messages": state["messages"] + [
                {"role": "assistant", "content": response, "name": "custom_agent"}
            ],
            "data": {**state["data"], "custom_analysis": analysis_result},
            "metadata": state["metadata"]
        }
        
        return new_state
        
    except Exception as e:
        logger.error(f"{ERROR_ICON} åˆ†æå¤±è´¥: {str(e)}")
        
        # é”™è¯¯æ¢å¤
        fallback_result = ErrorRecoveryStrategy.get_default_analysis_result(
            "custom_agent", str(e)
        )
        
        return {
            "messages": state["messages"],
            "data": {**state["data"], "custom_analysis": fallback_result},
            "metadata": state["metadata"]
        }
```

### é…ç½®é©±åŠ¨çš„LLMè°ƒç”¨

```python
from src.utils.config_manager import get_llm_config
from src.utils.llm_clients import LLMClientFactory

def intelligent_llm_call(messages, agent_name="unknown"):
    """é…ç½®é©±åŠ¨çš„æ™ºèƒ½LLMè°ƒç”¨"""
    config = get_llm_config()
    
    # æ ¹æ®é…ç½®é€‰æ‹©å®¢æˆ·ç«¯
    if config.openai_compatible_api_key:
        client = LLMClientFactory.create_client(
            client_type="openai_compatible",
            api_key=config.openai_compatible_api_key,
            base_url=config.openai_compatible_base_url,
            model=config.openai_compatible_model
        )
    else:
        client = LLMClientFactory.create_client(
            client_type="gemini",
            api_key=config.gemini_api_key,
            model=config.gemini_model
        )
    
    # æ‰§è¡Œè°ƒç”¨
    return client.get_completion(
        messages=messages,
        max_retries=config.max_retries
    )
```

### ç»Ÿä¸€é”™è¯¯å¤„ç†å’Œæ—¥å¿—

```python
from src.utils.exceptions import AShareAgentException
from src.utils.logging_config import setup_logger, ERROR_ICON
from src.utils.serialization import serialize_agent_state

logger = setup_logger('error_handler')

def safe_agent_execution(agent_func, state, agent_name):
    """å®‰å…¨çš„Agentæ‰§è¡ŒåŒ…è£…å™¨"""
    try:
        # åºåˆ—åŒ–è¾“å…¥çŠ¶æ€ç”¨äºè°ƒè¯•
        input_state = serialize_agent_state(state)
        logger.debug(f"Agent {agent_name} è¾“å…¥çŠ¶æ€: {input_state}")
        
        # æ‰§è¡ŒAgent
        result = agent_func(state)
        
        # åºåˆ—åŒ–è¾“å‡ºçŠ¶æ€
        output_state = serialize_agent_state(result)
        logger.debug(f"Agent {agent_name} è¾“å‡ºçŠ¶æ€: {output_state}")
        
        return result
        
    except AShareAgentException as e:
        logger.error(f"{ERROR_ICON} Agent {agent_name} æ‰§è¡Œå¤±è´¥: {str(e)}")
        # è¿”å›é”™è¯¯æ¢å¤çŠ¶æ€
        return create_error_state(state, agent_name, str(e))
    
    except Exception as e:
        logger.error(f"{ERROR_ICON} Agent {agent_name} æ„å¤–é”™è¯¯: {str(e)}")
        # è¿”å›é€šç”¨é”™è¯¯çŠ¶æ€
        return create_error_state(state, agent_name, f"æ„å¤–é”™è¯¯: {str(e)}")

def create_error_state(original_state, agent_name, error_msg):
    """åˆ›å»ºé”™è¯¯çŠ¶æ€"""
    from src.utils.exceptions import ErrorRecoveryStrategy
    
    fallback_result = ErrorRecoveryStrategy.get_default_analysis_result(
        agent_name, error_msg
    )
    
    return {
        "messages": original_state["messages"],
        "data": {
            **original_state["data"],
            f"{agent_name}_analysis": fallback_result
        },
        "metadata": {
            **original_state["metadata"],
            "error": True,
            "error_agent": agent_name,
            "error_message": error_msg
        }
    }
```

## é…ç½®ç®¡ç†æœ€ä½³å®è·µ

### ç¯å¢ƒé…ç½®ç®¡ç†

```python
# .env æ–‡ä»¶é…ç½®
GEMINI_API_KEY=your-key-here
OPENAI_COMPATIBLE_API_KEY=your-openai-key
OPENAI_COMPATIBLE_BASE_URL=https://api.openrouter.ai/api/v1
OPENAI_COMPATIBLE_MODEL=anthropic/claude-3-haiku

# ç³»ç»Ÿé…ç½®
LOG_LEVEL=INFO
CACHE_ENABLED=true
CACHE_TTL=3600

# Agenté…ç½®
DEFAULT_CONFIDENCE_THRESHOLD=0.5
MAX_NEWS_COUNT=100
```

### é…ç½®éªŒè¯

```python
from src.utils.config_manager import get_config

def validate_system_config():
    """éªŒè¯ç³»ç»Ÿé…ç½®"""
    config = get_config()
    
    if not config.validate_configuration():
        print("é…ç½®éªŒè¯å¤±è´¥ï¼")
        return False
        
    print("é…ç½®éªŒè¯é€šè¿‡")
    return True

# åœ¨ç³»ç»Ÿå¯åŠ¨æ—¶éªŒè¯é…ç½®
if __name__ == "__main__":
    if validate_system_config():
        # å¯åŠ¨ç³»ç»Ÿ
        main()
    else:
        exit(1)
```

### åŠ¨æ€é…ç½®é‡è½½

```python
from src.utils.config_manager import reload_config

def reload_system_config():
    """é‡æ–°åŠ è½½ç³»ç»Ÿé…ç½®"""
    try:
        reload_config()
        print("é…ç½®é‡è½½æˆåŠŸ")
    except Exception as e:
        print(f"é…ç½®é‡è½½å¤±è´¥: {e}")
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### LLMè°ƒç”¨ä¼˜åŒ–

```python
# ä½¿ç”¨è¿æ¥æ± å‡å°‘åˆå§‹åŒ–å¼€é”€
from src.utils.llm_clients import LLMClientFactory

class LLMClientPool:
    def __init__(self):
        self._clients = {}
    
    def get_client(self, client_type="auto"):
        if client_type not in self._clients:
            self._clients[client_type] = LLMClientFactory.create_client(client_type)
        return self._clients[client_type]

# å…¨å±€å®¢æˆ·ç«¯æ± 
client_pool = LLMClientPool()
```

### æ—¥å¿—æ€§èƒ½ä¼˜åŒ–

```python
# æ‰¹é‡æ—¥å¿—å†™å…¥
from src.utils.logging_config import setup_logger
import logging

# è®¾ç½®ç¼“å†²åŒºå¤§å°
logger = setup_logger('performance_agent')
for handler in logger.handlers:
    if isinstance(handler, logging.FileHandler):
        handler.flush = lambda: None  # ç¦ç”¨ç«‹å³åˆ·æ–°
        
# å®šæœŸæ‰‹åŠ¨åˆ·æ–°
import atexit
atexit.register(lambda: [h.flush() for h in logger.handlers])
```

### åºåˆ—åŒ–ä¼˜åŒ–

```python
from src.utils.serialization import serialize_agent_state
import json

def optimized_serialize(state, max_depth=5):
    """ä¼˜åŒ–çš„åºåˆ—åŒ–ï¼Œé™åˆ¶é€’å½’æ·±åº¦"""
    def limited_serialize(obj, depth=0):
        if depth > max_depth:
            return f"<max_depth_reached: {type(obj).__name__}>"
        
        # ä½¿ç”¨åŸå§‹åºåˆ—åŒ–é€»è¾‘ä½†é™åˆ¶æ·±åº¦
        return serialize_agent_state(obj)
    
    return limited_serialize(state)
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **é…ç½®åŠ è½½å¤±è´¥**
   ```python
   from src.utils.config_manager import get_config
   
   try:
       config = get_config()
   except Exception as e:
       print(f"é…ç½®åŠ è½½å¤±è´¥: {e}")
       # æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
   ```

2. **LLMè°ƒç”¨è¶…æ—¶**
   ```python
   # å¢åŠ è¶…æ—¶è®¾ç½®
   response = get_chat_completion(
       messages=messages,
       max_retries=5,
       client_type="auto"
   )
   ```

3. **æ—¥å¿—æ–‡ä»¶æƒé™é—®é¢˜**
   ```bash
   # ç¡®ä¿logsç›®å½•å­˜åœ¨ä¸”æœ‰å†™æƒé™
   mkdir -p logs
   chmod 755 logs
   ```

4. **åºåˆ—åŒ–å¤±è´¥**
   ```python
   # æ£€æŸ¥å¯¹è±¡æ˜¯å¦åŒ…å«ä¸å¯åºåˆ—åŒ–çš„å†…å®¹
   from src.utils.serialization import serialize_agent_state
   
   result = serialize_agent_state(state)
   if result.get("serialization_error"):
       print(f"åºåˆ—åŒ–é”™è¯¯: {result['error']}")
   ```

### è°ƒè¯•å·¥å…·

```python
# é…ç½®è°ƒè¯•ä¿¡æ¯
from src.utils.config_manager import get_config

config = get_config()
print("LLMé…ç½®:")
print(f"  Gemini API Key: {'å·²è®¾ç½®' if config.llm.gemini_api_key else 'æœªè®¾ç½®'}")
print(f"  OpenAI API Key: {'å·²è®¾ç½®' if config.llm.openai_compatible_api_key else 'æœªè®¾ç½®'}")

# LLMè°ƒç”¨è°ƒè¯•
from src.utils.llm_clients import get_chat_completion

def debug_llm_call(messages):
    print(f"å‘é€æ¶ˆæ¯: {messages}")
    response = get_chat_completion(messages, client_type="auto")
    print(f"æ”¶åˆ°å“åº”: {response}")
    return response

# æ—¥å¿—çº§åˆ«è°ƒè¯•
import logging
logging.getLogger().setLevel(logging.DEBUG)
```

### æ€§èƒ½ç›‘æ§

```python
import time
from src.utils.logging_config import setup_logger

logger = setup_logger('performance')

def monitor_execution(func_name):
    """æ‰§è¡Œæ—¶é—´ç›‘æ§è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            execution_time = time.time() - start_time
            logger.info(f"{func_name} æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
            return result
        return wrapper
    return decorator

# ä½¿ç”¨ç›‘æ§è£…é¥°å™¨
@monitor_execution("LLMè°ƒç”¨")
def monitored_llm_call(messages):
    return get_chat_completion(messages)
```

## æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„é…ç½®ç±»

```python
from dataclasses import dataclass
from src.utils.config_manager import ConfigManager

@dataclass
class NewFeatureConfig:
    """æ–°åŠŸèƒ½é…ç½®"""
    feature_enabled: bool = True
    feature_timeout: int = 30

# æ‰©å±•ConfigManager
class ExtendedConfigManager(ConfigManager):
    def __init__(self):
        super().__init__()
        self._new_feature_config = self._load_new_feature_config()
    
    def _load_new_feature_config(self) -> NewFeatureConfig:
        return NewFeatureConfig(
            feature_enabled=os.getenv("NEW_FEATURE_ENABLED", "true").lower() == "true",
            feature_timeout=int(os.getenv("NEW_FEATURE_TIMEOUT", "30"))
        )
    
    @property
    def new_feature(self) -> NewFeatureConfig:
        return self._new_feature_config
```

### è‡ªå®šä¹‰LLMå®¢æˆ·ç«¯

```python
from src.utils.llm_clients import LLMClient

class CustomLLMClient(LLMClient):
    """è‡ªå®šä¹‰LLMå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key, custom_param):
        self.api_key = api_key
        self.custom_param = custom_param
    
    def get_completion(self, messages, **kwargs):
        # å®ç°è‡ªå®šä¹‰LLMè°ƒç”¨é€»è¾‘
        return self._call_custom_api(messages)
    
    def _call_custom_api(self, messages):
        # å…·ä½“å®ç°
        pass

# æ³¨å†Œåˆ°å·¥å‚
from src.utils.llm_clients import LLMClientFactory

def create_custom_client(**kwargs):
    return CustomLLMClient(**kwargs)

# æ‰©å±•å·¥å‚æ–¹æ³•
original_create = LLMClientFactory.create_client

def extended_create_client(client_type="auto", **kwargs):
    if client_type == "custom":
        return create_custom_client(**kwargs)
    return original_create(client_type, **kwargs)

LLMClientFactory.create_client = extended_create_client
```

### è‡ªå®šä¹‰å¼‚å¸¸ç±»

```python
from src.utils.exceptions import AShareAgentException

class NewFeatureError(AShareAgentException):
    """æ–°åŠŸèƒ½ç›¸å…³é”™è¯¯"""
    def __init__(self, message: str, feature_name: str = None):
        self.feature_name = feature_name
        super().__init__(message)

# æ‰©å±•é”™è¯¯æ¢å¤ç­–ç•¥
from src.utils.exceptions import ErrorRecoveryStrategy

class ExtendedErrorRecovery(ErrorRecoveryStrategy):
    @staticmethod
    def get_new_feature_fallback():
        return {"status": "fallback", "error": "æ–°åŠŸèƒ½æ‰§è¡Œå¤±è´¥"}
```

è¿™ä¸ªç»¼åˆçš„README.mdæ–‡æ¡£æ¶µç›–äº†æ™ºèƒ½æŠ•èµ„ç³»ç»Ÿutilsæ¨¡å—çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼Œæä¾›äº†è¯¦ç»†çš„ä½¿ç”¨æŒ‡å—ã€é…ç½®è¯´æ˜ã€é›†æˆç¤ºä¾‹å’Œæ‰©å±•å¼€å‘æŒ‡å¯¼ï¼Œå¸®åŠ©å¼€å‘è€…å…¨é¢ç†è§£å’Œæœ‰æ•ˆä½¿ç”¨è¿™äº›åŸºç¡€å·¥å…·ç»„ä»¶ã€‚